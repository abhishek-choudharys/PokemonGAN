# -*- coding: utf-8 -*-
"""PokemonWGAN2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wVrs339_LozcOzARIX55Q0uhxtoP8viF
"""

!git clone https://github.com/abhishek-choudharys/PokemonGAN

cd ../content/PokemonGAN

run resize.py

run convertRGBAtoRGB.py

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import tensorflow as tf
from tensorflow import keras
import numpy as np
#import plot_utils
import matplotlib.pyplot as plt
from tqdm import tqdm
from IPython import display
from numpy import mean

print('Tensorflow version: ', tf.__version__)

import cv2
import os

def load_images_from_folder(folder):
    images = []
    for filename in os.listdir(folder):
        img = cv2.imread(os.path.join(folder,filename))
        img_rgb = img[:, :, [2, 1, 0]]
        if img_rgb is not None:
            images.append(img_rgb)
    return images

images = load_images_from_folder('resized_RGB')
type(images)

import random
def grab_batch(images, batch_size):
    image_batch = np.zeros([32, 256, 256, 3])
    #image_batchx = np.empty()
    #print(np.asarray(random.sample(images, 1)).shape)
    for i in range(0, batch_size):
        image_batch[i,:,:,:] = np.asarray(random.sample(images, 1))[:,:,:]
        #image_batchx = np.append(image_batchx, np.asarray(random.sample(images, 1))[:,:,:])
    
    return image_batch*(1./255)
    
image_batch = np.asarray(grab_batch(images, 32))

print(type(image_batch))
print(image_batch.shape)

def show_batch(image_batch):
  #print(type(image_batch))
  plt.figure(figsize=(10,10))
  for n in range(25):
      ax = plt.subplot(5,5,n+1)
      #plt.imshow(np.float32(image_batch[n]))
      plt.imshow(image_batch[n])
      plt.axis('off')

def generate_and_save_images(model, epoch, test_input):
    predictions = model(test_input, training = False)
    fig = plt.figure(figsize = (10,10))

    for i in range(25):
        plt.subplot(5, 5, i+1)
        plt.imshow(np.uint8(predictions[i, :, :, :] * 127.5 + 127.5))
        plt.axis('off')
    
    plt.savefig('image_at_each_epoch_{:04d}.png'.format(epoch))
    plt.show()

show_batch(image_batch) #from custom grab

from keras import backend

# implementation of wasserstein loss
def wasserstein_loss(y_true, y_pred):
	return backend.mean(y_true * y_pred)

from keras.constraints import Constraint

class ClipConstraint(Constraint):
	# set clip value when initialized
	def __init__(self, clip_value):
		self.clip_value = clip_value
 
	# clip model weights
	def __call__(self, weights):
		return backend.clip(weights, -self.clip_value, self.clip_value)
 
	# get the config
	def get_config(self):
		return {'clip_value': self.clip_value}

#init an object of the class
const = ClipConstraint(0.01)

num_features = 100

generator = keras.models.Sequential([
                                    keras.layers.Dense(8*8*256, input_shape = [num_features]), #dense layer
                                    keras.layers.Reshape([8,8,256]), #reshaped to 7*7 of 128
                                    keras.layers.BatchNormalization(),
                                    keras.layers.Conv2DTranspose(512, (5,5), (2,2), padding='same', activation='selu'),
                                    keras.layers.BatchNormalization(),
                                    keras.layers.Conv2DTranspose(128, (5,5), (2,2), padding='same', activation='selu'),
                                    keras.layers.BatchNormalization(),
                                    keras.layers.Conv2DTranspose(64, (5,5), (2,2), padding='same', activation='selu'),
                                    keras.layers.BatchNormalization(),
                                    keras.layers.Conv2DTranspose(32, (5,5), (2,2), padding='same', activation='selu'),
                                    keras.layers.BatchNormalization(),
                                    keras.layers.Conv2DTranspose(3, (5,5), (2,2), padding='same', activation='tanh'),
])

generator.summary()

noise = tf.random.normal(shape = [1, num_features])

generated_image = generator(noise, training = False)
#show(generated_image, 1)

discriminator = keras.models.Sequential([
                                         keras.layers.Conv2D(64, (5,5), (2,2), padding='same', input_shape = [256, 256, 3], kernel_constraint=const),
                                         keras.layers.LeakyReLU(0.2),
                                         keras.layers.Dropout(0.3),
                                         keras.layers.Conv2D(128, (5,5), (2,2), padding='same', kernel_constraint=const),
                                         keras.layers.LeakyReLU(0.2),
                                         keras.layers.Dropout(0.3),
                                         keras.layers.Conv2D(256, (5,5), (2,2), padding='same', kernel_constraint=const),
                                         keras.layers.LeakyReLU(0.2),
                                         keras.layers.Dropout(0.3),
                                         keras.layers.Conv2D(512, (5,5), (2,2), padding='same', kernel_constraint=const),
                                         keras.layers.LeakyReLU(0.2),
                                         keras.layers.Dropout(0.3),
                                         keras.layers.Flatten(),
                                         keras.layers.Dense(1, activation = 'linear'),
                                         
])

discriminator.summary()

from keras.optimizers import RMSprop
opt = RMSprop(lr=0.00005)

discriminator_output = discriminator(generated_image, training=False)
print(discriminator_output)

discriminator.compile(loss = wasserstein_loss, optimizer = 'rmsprop')
discriminator.trainable = False

gan = keras.models.Sequential([generator, discriminator])
gan.compile(loss = wasserstein_loss, optimizer = 'rmsprop')

batch_size = 32
seed = tf.random.normal(shape = [batch_size, num_features])

def show(images, n_cols = None):
    n_cols = n_cols or len(images)
    n_rows = (len(images) - 1) // n_cols + 1

    if(images.shape[-1] == 1):
        images = np.squeeze(images, axis=-1)
    
    plt.figure(figsize = (n_cols, n_rows))
    for index, image in enumerate(images):
        plt.subplot(n_cols, n_rows, index+1)
        plt.imshow(np.uint8(image))
        plt.axis("off")

noise = tf.random.normal(shape = [1, num_features])
print("Noise : ", noise[0,:10])
generated_image = generator(noise, training = False)
show(generated_image, 1)
decision = discriminator(generated_image)
print("Decision: ", decision)

def plot_history(d1_hist, d2_hist, g_hist):
    plt.figure()
    plt.plot(d1_hist, label='crit_real')
    plt.plot(d2_hist, label='crit_fake')
    plt.plot(g_hist, label='gen')
    plt.legend()
    plt.savefig('plot_line_plot_loss.png')
    plt.show()
    plt.close()

def train_wgan(gan, batch_size, num_features, epochs = 5, steps = 5, critic_steps = 5):
    generator, discriminator = gan.layers

    c1_hist_all, c2_hist_all, g_hist_all = list(), list(), list()
    for epoch in tqdm(range(epochs)):

        print("Epoch : {}/{}".format(epoch+1, epochs))

        #keep track of loss
        c1_hist, c2_hist, g_hist = list(), list(), list()
        
        for i in range(steps):

            for j in range(critic_steps):

                c1_tmp, c2_tmp = list(), list()

                X_batch = grab_batch(images, batch_size)

                discriminator.trainable = True

                #discriminator on real samples
                X_real = tf.concat([X_batch], axis = 0)
                y = tf.constant([[-1.]]*batch_size)
                c_loss1 = discriminator.train_on_batch(X_real, y)
                c1_tmp.append(c_loss1)

                #discriminator on fake samples
                y = tf.constant([[1.]]*batch_size)
                noise = tf.random.normal(shape = [batch_size, num_features])
                X_fake = generator(noise)
                c_loss2 = discriminator.train_on_batch(X_fake, y)
                c2_tmp.append(c_loss2)

                discriminator.trainable = False
                #

            c1_hist.append(mean(c1_tmp))
            c2_hist.append(mean(c2_tmp))
            c1_hist_all.append(mean(c1_tmp))
            c2_hist_all.append(mean(c2_tmp))
            noise = tf.random.normal(shape = [batch_size, num_features])
            generated_images = generator(noise)
            
            #not needed, just to compare
            #X_fake_and_real = tf.concat([generated_images, X_batch], axis = 0)
            #show_batch(X_fake_and_real)
            
            y2 = tf.constant([[-1.]] * batch_size)               
            g_loss = gan.train_on_batch(noise, y2)
            g_hist.append(g_loss)
            g_hist_all.append(g_loss)

        # line plots of loss
        plot_history(c1_hist, c2_hist, g_hist)
        display.clear_output(wait = True)

        noise = tf.random.normal(shape = [batch_size, num_features])
        generated_images = generator(noise)
        #show_batch(generated_images)

        #generate_and_save_images(generator, epoch+1, seed)
    plot_history(c1_hist_all, c2_hist_all, g_hist_all)
    show_batch(generated_images)
    generate_and_save_images(generator, epochs, seed)

tf.config.experimental_run_functions_eagerly(True)

train_wgan(gan, batch_size, num_features, epochs=10, steps = 5, critic_steps = 5)
