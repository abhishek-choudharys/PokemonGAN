# -*- coding: utf-8 -*-
"""PokemonWGAN3-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lbRU0cNKSHVNvAg5CX5hvaUGrvuqhFoJ
"""
'''
!pip install kaggle

!mkdir .kaggle

import os
os.getcwd()

import json
token = {"username":"","key":""}
with open('/content/.kaggle/kaggle.json', 'w') as file:
    json.dump(token, file)

cd content

!ls -a

filename = "../root/.kaggle/demo.json"
os.makedirs(os.path.dirname(filename), exist_ok=True)

!cp .kaggle/kaggle.json ../root/.kaggle/kaggle.json

!chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets list

!git clone https://github.com/abhishek-choudharys/PokemonGAN

!kaggle config set -n path -v/content/PokemonGAN

!kaggle datasets download -d kvpratama/pokemon-images-dataset

!pip install -i https://test.pypi.org/simple/ supportlib

cd ../content/PokemonGAN

import supportlib.gettingdata as sl
sl.zipextract('datasets/kvpratama/pokemon-images-dataset/pokemon-images-dataset.zip')

rm -r pokemon/pokemon

import os
import cv2

src = "pokemon/"
dest = "resizedData"

os.mkdir(dest)

for i in os.listdir(src):
    img = cv2.imread(os.path.join(src, i))
    img = cv2.resize(img, (256, 256))
    cv2.imwrite(os.path.join(dest,i), img) #resized images are written in a new folder

import os
from PIL import Image

src = "resizedData"
dest = "resized_RGB"

os.mkdir(dest)

for i in os.listdir(src):
    img = Image.open(os.path.join(src, i))

    if img.mode == 'RGBA':
        img.load()
        bg = Image.new("RGB", img.size, (0,0,0))
        bg.paste(img, mask = img.split()[3]) #we paste img in bg using alpha channel as mask
        bg.save(os.path.join(dest, i.split('.')[0] + '.jpg'), 'JPEG') #save the images as jpeg, split dest at '.' and take first split
    else:
        img.convert('RGB')
        img.save(os.path.join(dest,i.split('.')[0] + '.jpg'), 'JPEG') #save the images as jpeg
'''
# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import tensorflow as tf
from tensorflow import keras
import numpy as np
#import plot_utils
import matplotlib.pyplot as plt
from tqdm import tqdm
from IPython import display
from numpy import mean

print('Tensorflow version: ', tf.__version__)

import cv2
import os

def load_images_from_folder(folder):
    images = []
    for filename in os.listdir(folder):
        img = cv2.imread(os.path.join(folder,filename))
        img_rgb = img[:, :, [2, 1, 0]]
        if img_rgb is not None:
            images.append(img_rgb)
    return images

images = load_images_from_folder('../resized_RGB')
type(images)

import random
def grab_batch(images, batch_size):
    image_batch = np.zeros([32, 256, 256, 3])
    #image_batchx = np.empty()
    #print(np.asarray(random.sample(images, 1)).shape)
    for i in range(0, batch_size):
        image_batch[i,:,:,:] = np.asarray(random.sample(images, 1))[:,:,:]
        #image_batchx = np.append(image_batchx, np.asarray(random.sample(images, 1))[:,:,:])
    
    #return image_batch*(1./255)
    return image_batch*(1./127.5) - 1
    
image_batch = np.asarray(grab_batch(images, 32))

print(type(image_batch))
print(image_batch.shape)

def generate_and_save_images(model, epoch, test_input):
    predictions = model(test_input, training = False)
    fig = plt.figure(figsize = (10,10))

    for i in range(25):
        plt.subplot(5, 5, i+1)
        plt.imshow(np.uint8(predictions[i, :, :, :] * 127.5 + 127.5))
        plt.axis('off')
    
    plt.savefig('image_at_each_epoch_{:04d}.png'.format(epoch))
    plt.show()

def show_batch(image_batch):
  #print(type(image_batch))
  plt.figure(figsize=(10,10))
  for n in range(25):
      ax = plt.subplot(5,5,n+1)
      #plt.imshow(np.float32(image_batch[n]))
      plt.imshow(np.uint8((image_batch[n] * 127.5) + 127.5))
      plt.axis('off')

show_batch(image_batch) #from custom grab

from keras import backend

# implementation of wasserstein loss
def wasserstein_loss(y_true, y_pred):
	return backend.mean(y_true * y_pred)

from keras.constraints import Constraint

class ClipConstraint(Constraint):
	# set clip value when initialized
	def __init__(self, clip_value):
		self.clip_value = clip_value
 
	# clip model weights
	def __call__(self, weights):
		return backend.clip(weights, -self.clip_value, self.clip_value)
 
	# get the config
	def get_config(self):
		return {'clip_value': self.clip_value}

#init an object of the class
const = ClipConstraint(0.01)

num_features = 100

generator = keras.models.Sequential([
                                    keras.layers.Dense(8*8*256, input_shape = [num_features]), #dense layer
                                    keras.layers.Reshape([8,8,256]), #reshaped to 7*7 of 128
                                    keras.layers.BatchNormalization(),
                                    keras.layers.Conv2DTranspose(512, (5,5), (2,2), padding='same', activation='selu'),
                                    keras.layers.BatchNormalization(),
                                    keras.layers.Conv2DTranspose(128, (5,5), (2,2), padding='same', activation='selu'),
                                    keras.layers.BatchNormalization(),
                                    keras.layers.Conv2DTranspose(64, (5,5), (2,2), padding='same', activation='selu'),
                                    keras.layers.BatchNormalization(),
                                    keras.layers.Conv2DTranspose(32, (5,5), (2,2), padding='same', activation='selu'),
                                    keras.layers.BatchNormalization(),
                                    keras.layers.Conv2DTranspose(3, (5,5), (2,2), padding='same', activation='tanh'),
])

generator.summary()

noise = tf.random.normal(shape = [1, num_features])

generated_image = generator(noise, training = False)
#show(generated_image, 1)

discriminator = keras.models.Sequential([
                                         keras.layers.Conv2D(64, (5,5), (2,2), padding='same', input_shape = [256, 256, 3], kernel_constraint=const),
                                         keras.layers.LeakyReLU(0.2),
                                         keras.layers.Dropout(0.3),
                                         keras.layers.Conv2D(128, (5,5), (2,2), padding='same', kernel_constraint=const),
                                         keras.layers.LeakyReLU(0.2),
                                         keras.layers.Dropout(0.3),
                                         keras.layers.Conv2D(256, (5,5), (2,2), padding='same', kernel_constraint=const),
                                         keras.layers.LeakyReLU(0.2),
                                         keras.layers.Dropout(0.3),
                                         keras.layers.Conv2D(512, (5,5), (2,2), padding='same', kernel_constraint=const),
                                         keras.layers.LeakyReLU(0.2),
                                         keras.layers.Dropout(0.3),
                                         keras.layers.Flatten(),
                                         keras.layers.Dense(1, activation = 'linear'),
                                         
])

discriminator.summary()

from keras.optimizers import RMSprop
opt = RMSprop(lr=0.00005)

discriminator_output = discriminator(generated_image, training=False)
print(discriminator_output)

discriminator.compile(loss = wasserstein_loss, optimizer = 'rmsprop')
discriminator.trainable = False

gan = keras.models.Sequential([generator, discriminator])
gan.compile(loss = wasserstein_loss, optimizer = 'rmsprop')
gan.trainable = True

batch_size = 32
seed = tf.random.normal(shape = [batch_size, num_features])

def show(images, n_cols = None):
    n_cols = n_cols or len(images)
    n_rows = (len(images) - 1) // n_cols + 1

    if(images.shape[-1] == 1):
        images = np.squeeze(images, axis=-1)
    
    plt.figure(figsize = (n_cols, n_rows))
    for index, image in enumerate(images):
        plt.subplot(n_cols, n_rows, index+1)
        plt.imshow(np.uint8(image * 127.5 + 127.5))
        plt.axis("off")

noise = tf.random.normal(shape = [1, num_features])
print("Noise : ", noise[0,:10])
generated_image = generator(noise, training = False)
show(generated_image, 1)
decision = discriminator(generated_image)
print("Decision: ", decision)

def plot_history(d1_hist, d2_hist, g_hist):
    plt.figure()
    plt.plot(d1_hist, label='crit_real')
    plt.plot(d2_hist, label='crit_fake')
    plt.plot(g_hist, label='gen')
    plt.legend()
    plt.savefig('plot_line_plot_loss.png')
    plt.show()
    plt.close()

c1_hist_all, c2_hist_all, g_hist_all = list(), list(), list()
def train_wgan(gan, batch_size, num_features, c1_hist_all, c2_hist_all, g_hist_all, epochs = 5, steps = 15, critic_steps = 5):
    generator, discriminator = gan.layers

    #c1_hist_all, c2_hist_all, g_hist_all = list(), list(), list()
    for epoch in tqdm(range(epochs)):

        print("Epoch : {}/{}".format(epoch+1, epochs))

        #keep track of loss
        c1_hist, c2_hist, g_hist = list(), list(), list()
        
        for i in range(steps):

            for j in range(critic_steps):

                c1_tmp, c2_tmp = list(), list()

                X_batch = grab_batch(images, batch_size)

                discriminator.trainable = True

                #discriminator on real samples
                #X_real = tf.concat([X_batch], axis = 0)
                X_real = X_batch
                y = tf.constant([[-1.]]*batch_size)
                c_loss1 = discriminator.train_on_batch(X_real, y)
                c1_tmp.append(c_loss1)

                #discriminator on fake samples
                y = tf.constant([[1.]]*batch_size)
                noise = tf.random.normal(shape = [batch_size, num_features])
                X_fake = generator(noise)
                c_loss2 = discriminator.train_on_batch(X_fake, y)
                c2_tmp.append(c_loss2)

                discriminator.trainable = False
                #

            c1_hist.append(mean(c1_tmp))
            c2_hist.append(mean(c2_tmp))
            c1_hist_all.append(mean(c1_tmp))
            c2_hist_all.append(mean(c2_tmp))
            noise = tf.random.normal(shape = [batch_size, num_features])
            generated_images = generator(noise)
            
            #not needed, just to compare
            #X_fake_and_real = tf.concat([generated_images, X_batch], axis = 0)
            #show_batch(X_fake_and_real)
            
            y2 = tf.constant([[-1.]] * batch_size)             
            g_loss = gan.train_on_batch(noise, y2)
            g_hist.append(g_loss)
            g_hist_all.append(g_loss)

        # line plots of loss
        display.clear_output(wait = True)
        plot_history(c1_hist_all, c2_hist_all, g_hist_all)

        noise = tf.random.normal(shape = [batch_size, num_features])
        generated_images = generator(noise)
        show_batch(generated_images)
        #show_batch(generated_images)

        #generate_and_save_images(generator, epoch+1, seed)
    plot_history(c1_hist_all, c2_hist_all, g_hist_all)
    show_batch(generated_images)
    #generate_and_save_images(generator, epochs, seed)

tf.config.experimental_run_functions_eagerly(True)

from keras import backend as K

def reset_weights(model):
    for layer in model.layers:
        if isinstance(layer, tf.keras.Model): #if you're using a model as a layer
            reset_weights(layer) #apply function recursively
            continue

        #where are the initializers?
        if hasattr(layer, 'cell'):
            init_container = layer.cell
        else:
            init_container = layer

        for key, initializer in init_container.__dict__.items():
            if "initializer" not in key: #is this item an initializer?
                  continue #if no, skip it

            # find the corresponding variable, like the kernel or the bias
            if key == 'recurrent_initializer': #special case check
                var = getattr(init_container, 'recurrent_kernel')
            else:
                var = getattr(init_container, key.replace("_initializer", ""))

            var.assign(initializer(var.shape, var.dtype))
            #use the initializer

reset_weights(gan)

train_wgan(gan, batch_size, num_features, c1_hist_all, c2_hist_all, g_hist_all, epochs=20, steps = 20, critic_steps = 5)

'''
from google.colab import drive
drive.mount('/content/gdrive')

from keras.callbacks import *
filepath="/content/gdrive/My Drive/WGAN3-2/save.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

os.getcwd()

from keras.models import model_from_json
model_json = gan.to_json()
with open("../gdrive/My Drive/model2.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
gan.save_weights("../gdrive/My Drive/model2.h5")
print("Saved model to disk")

gan.load_weights('../gdrive/My Drive/model2.h5')

import tensorflow as tf 
gan = tf.keras.models.load_model('../gdrive/My Drive/model2.h5')

import argparse

from keras.models import model_from_json
json_file = open(args.model.replace("../gdrive/My Drive/model2.h5","../gdrive/My Drive/model2.json"), 'r')
loaded_model_json = json_file.read()
json_file.close()
model = model_from_json(loaded_model_json)
gan.load_weights(args.model)
# load weights into new model
#gan.load_weights("../gdrive/My Drive/model2.h5")
#print("Loaded model from disk")
'''
